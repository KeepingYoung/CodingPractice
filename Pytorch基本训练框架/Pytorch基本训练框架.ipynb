{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71479bb9-2371-4e58-a632-f485b493dac8",
   "metadata": {},
   "source": [
    "# Pytorch基本训练框架"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca39f0-c310-41ec-9bae-657a202f249a",
   "metadata": {},
   "source": [
    "## 基本组件1: 神经网络\n",
    "1. 所有的Pytorch神经网络都必须继承自一个基类: nn.Module\n",
    "2. 两个最重要的函数:\n",
    "    1. 构造函数 __init__ : 定义所有成员变量, 也就是网络结构\n",
    "    2. forward()函数: 定义网络的前向过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5a5b1b8-e9c6-4d56-839b-f23754e8cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义网络\n",
    "class TestNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(784,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        B,C,W,H = x.shape\n",
    "        x = x.view(B,W*H)\n",
    "        return self.net(x)\n",
    "\n",
    "# 初始化网络\n",
    "model = TestNet().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c87274-8441-443d-ab97-e5a9bf832837",
   "metadata": {},
   "source": [
    "## 基本组件2: 优化器\n",
    "1. 优化器一般不用自己写, 通常继承自: torch.optim.Optimizer\n",
    "2. 优化器的构造函数中必须定义该优化器对应的可优化参数\n",
    "3. 例如learning rate, weight decay, momentum 之类的都是不同优化器的可调节参数，这些参数对最终模型的性能影响非常大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "362c1974-81d3-4172-a0f0-347ab8a98b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "optimizer = Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446c848-f5b9-4923-bae4-02d0b6e4e733",
   "metadata": {},
   "source": [
    "## 基本组件3: 损失函数\n",
    "1. 损失函数可以自己任意定义，一般来说输出是一个标量的损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4585767e-2609-42cd-a3a4-0104efe50321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f785c-3661-4be1-91c6-c05947e029fd",
   "metadata": {},
   "source": [
    "## 定义训练函数\n",
    "有了上述三个组件，我们就可以定义训练过程了，在很多框架中，下面的这个函数被称为trainer\n",
    "\n",
    "trainer 定义了训练中一个完整的正向、反向传播过程\n",
    "\n",
    "trainer 不一定有返回值,一般会返回loss的数值进行可视化，在这个过程中，重要的是model这个对象的所有参数获得了更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "023a8fe6-f436-4597-9cbc-64bc97c7aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意loss_func不一定通过传参形式给到trainer, 可以直接import\n",
    "# device 是CPU或CUDA, 或者特定编号的GPU\n",
    "def trainer(batch, model, optimizer, loss_func, device):\n",
    "    # 将模型参数设为训练模式\n",
    "    model.train()\n",
    "    # 从batch中获取输入数据和标签(不一定有标签)\n",
    "    x, y = batch\n",
    "    # 将数据存入对应设备中\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    # 梯度清零\n",
    "    optimizer.zero_grad()\n",
    "    # 前向传播\n",
    "    y_hat = model(x)\n",
    "    # 计算loss\n",
    "    loss = loss_func(y_hat,y)\n",
    "    # 反向传播获取梯度\n",
    "    loss.backward()\n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "\n",
    "    # 计算准确率\n",
    "    predictions = torch.argmax(y_hat, dim=1)  # 获取模型的预测结果\n",
    "    correct_predictions = (predictions == y).sum().item()  # 统计正确的预测数量\n",
    "    return loss.item() / y.shape[0], correct_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aca094-99f8-4d6d-bc9c-6d6c2f3f2a66",
   "metadata": {},
   "source": [
    "## 定义验证函数\n",
    "1. 验证函数需要将模型设置为预测模式\n",
    "2. 需要输入validation loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0de5adb-1f7e-4e8f-9057-aa99c8f550ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, loss_func, device):\n",
    "    # 将模型参数设为评估模式\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for batch in val_loader:\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = model(x)\n",
    "            # 计算loss\n",
    "            loss = loss_func(y_hat, y)\n",
    "\n",
    "            total_loss += loss.item() / y.size(0)\n",
    "\n",
    "            # 计算准确率\n",
    "            predictions = torch.argmax(y_hat, dim=1)\n",
    "            correct_predictions += (predictions == y).sum().item()\n",
    "            total_samples += y.size(0)\n",
    "\n",
    "    # 计算平均损失和准确率\n",
    "    average_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"Validation Loss: {average_loss:.4f} | Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a34964-8199-4fe2-91e8-4453904617d3",
   "metadata": {},
   "source": [
    "## 输入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbb5f0-d122-48cd-accd-587d662480bf",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "1. 数据集通常继承自: torch.utils.data.Dataset 基类\n",
    "2. 对于图像中的常用数据集, 一般会在torchvision库中有定义好的Dataset类\n",
    "3. 对于不常用的数据集，往往需要手写Dataset类, 手写Dataset类时一定需要的是__getitem__方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2136d1a7-d087-48b9-b61f-7d9444415ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# 定义数据集的转换\n",
    "my_transform = T.Compose([\n",
    "    T.ToTensor(),  # 将图像转换为张量\n",
    "    T.Normalize((0.5,), (0.5,))  # 标准化张量，使其范围在[-1, 1]之间\n",
    "])\n",
    "\n",
    "# 初始化训练集和测试集\n",
    "train_dataset = MNIST(root='./data', train=True, transform=my_transform, download=True)\n",
    "test_dataset = MNIST(root='./data', train=False, transform=my_transform, download=True)\n",
    "\n",
    "# 自定义数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data = [0 for i in range(100)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea8368-6fd8-4fb4-b64b-f56aa4438f48",
   "metadata": {},
   "source": [
    "## 数据读取\n",
    "1. DataLoader可以从数据集中读取不同batch的数据，可以通过定义num_workers来定义数据读取线程的数量, 通过pin_memory来决定数据是否要存放在内存条中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98d4be2a-09a8-4e5a-a71c-e9f72187f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义 DataLoader 来加载数据\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45202aeb-af5e-4134-9460-ad150a9f79ef",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abb20f54-95b4-4a94-bfa1-629c61a5bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "total_ep = 100\n",
    "for ep in range(total_ep):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for batch in train_loader:\n",
    "        loss, correct_predictions = trainer(batch, model, optimizer, loss_func, device)\n",
    "        total_loss += loss\n",
    "        total_correct += correct_predictions\n",
    "        total_samples += batch[1].shape[0]\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f\"Epoch: {ep} Training Loss: {average_loss:.4f} | Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "    if (ep+1) % 5 == 0:\n",
    "        validate(test_loader, model, loss_func, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976de4a0-5b14-4a6e-a655-f7b787f92e16",
   "metadata": {},
   "source": [
    "## 结果输出\n",
    "1. 可以输出到txt文件\n",
    "2. 直接使用print\n",
    "3. 使用tensorboard等工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da09a1-32bf-4587-80e1-fcb2c7f9b7b1",
   "metadata": {},
   "source": [
    "# Tips\n",
    "1. 代码需要遵循“高内聚，低耦合”的设计思路，既每个函数、每个类都只完成最少的任务，这样才方便修改，快速移植\n",
    "2. 善于组合别人的代码，将别人的模块化用到自己的代码中"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
